--- 
layout: post
title: Machine Learning Ex3 - Multivariate Linear Regression
categories: 
- r
- machinelearning
- regressionanalysis
- statistics
---







<p>
<a href="http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&amp;doc=exercises/ex3/ex3.html">Exercise 3</a> is about multivariate linear regression. First part is about finding a good learning rate (alpha) and 2nd part is about implementing linear regression using normal equations instead of the gradient descent algorithm.
</p>


<script src="http://www.mathjax.org/mathjax/MathJax.js" type="text/javascript">
    MathJax.Hub.Config({
            jax: ["input/TeX", "output/HTML-CSS"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                     "TeX/noUndefined.js"],
        tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
        },
        showProcessingMessages: true,
        displayAlign: "left",
        displayIndent: "2em",
 
        "HTML-CSS": {
             scale: 100,
             availableFonts: ["STIX","TeX"],
             preferredFont: "TeX",
             webFont: "TeX",
             imageFont: "TeX",
             showMathMenu: true,
        },
        MMLorHTML: {
             prefer: {
                 MSIE:    "MML",
                 Firefox: "MML",
                 Opera:   "HTML",
                 other:   "HTML"
             }
        }
    });
</script>



<div class="outline-2" id="outline-container-1">
<h2 id="sec-1">Data </h2>
<div class="outline-text-2" id="text-1">


<p>
As usual hosted in google docs:
</p>


<pre class="src src-R">mydata = read.csv(<span style="color: #8b2252;">"http://spreadsheets.google.com/pub?key=0AnypY27pPCJydExfUzdtVXZuUWphM19vdVBidnFFSWc&amp;output=csv"</span>, header = <span style="color: #228b22;">TRUE</span>)

<span style="color: #b22222;"># </span><span style="color: #b22222;">show last 5 rows
</span>tail(mydata, 5)
</pre>



<pre class="example">
   area bedrooms  price
43 2567        4 314000
44 1200        3 299000
45  852        2 179900
46 1852        4 299900
47 1203        3 239500
</pre>



</div>

<div class="outline-3" id="outline-container-1_1">
<h3 id="sec-1_1">Feature Scaling </h3>
<div class="outline-text-3" id="text-1_1">


<p>
When applying the gradient descent, we need to make sure that features values are in the same order of magnitudes, otherwise it will not converge well, so here's a helper function to scale features:
</p>



<pre class="src src-R"><span style="color: #b22222;"># </span><span style="color: #b22222;">given a data frame and the column names i want to scale
</span><span style="color: #b22222;"># </span><span style="color: #b22222;">creates new columns: feature.scale = (feature - mean)/std
</span>feature.scale = <span style="color: #7f007f;">function</span> (dta, cols) {
  <span style="color: #7f007f;">for</span> (col <span style="color: #7f007f;">in</span> cols) {
    sigma = sd(dta[col])
    mu = mean(dta[col])
    dta[paste(names(dta[col]), <span style="color: #8b2252;">".scale"</span>, sep = <span style="color: #8b2252;">""</span>)] = (dta[col] - mu)/sigma
  }
  <span style="color: #7f007f;">return</span>(dta)
}

dta = feature.scale(mydata, c(<span style="color: #8b2252;">"area"</span>, <span style="color: #8b2252;">"bedrooms"</span>))
tail(dta, 5)
</pre>



<pre class="example">
   area bedrooms  price area.scale bedrooms.scale
43 2567        4 314000   0.712618      1.0904165
44 1200        3 299000  -1.007523     -0.2236752
45  852        2 179900  -1.445423     -1.5377669
46 1852        4 299900  -0.187090      1.0904165
47 1203        3 239500  -1.003748     -0.2236752
</pre>


</div>
</div>

</div>

<div class="outline-2" id="outline-container-2">
<h2 id="sec-2">Finding Alpha(\(\alpha\)) </h2>
<div class="outline-text-2" id="text-2">


<p>
Recall from <a href="http://al3xandr3.github.com/2011/02/24/ml-ex2-linear-regression.html">ex2</a> that the gradient descent equation for the updates of theta is:
</p>


\[
\theta := \theta - \alpha \frac{1}{m} x^T (x\theta^T - y)
\]

<p>
For finding a good alpha(\(\alpha\)) we will use a trial and error approach. The idea is look at how the Cost value \(J(\alpha)\) drops with the number of iterations, the fastest the drop the better, but if goes up then the alpha value is already too large.
</p>
<p>
The Cost is given by(in vectorized form):
</p>


\[
J(\theta) = \frac{1}{2m} (X\theta - y)^T (X\theta - y)
\]

<p>
See the lessons on details how to reach that equation.
</p>
<p>
Implementing:
</p>



<pre class="src src-R"><span style="color: #b22222;"># </span><span style="color: #b22222;">lets try out a few alpha's
</span>alpha = c(0.03, 0.1, 0.3, 1, 1.3, 2)

<span style="color: #b22222;"># </span><span style="color: #b22222;">store the J values over the iterations
</span>J = array(0,c(50,length(alpha)))
m = length(dta$price)
theta = matrix(c(0,0,0), nrow=1)
x = matrix(c(rep(1,m), dta$area.scale, dta$bedrooms.scale), ncol=3)
y = matrix(dta$price, ncol=1)

<span style="color: #b22222;"># </span><span style="color: #b22222;">the delta updates
</span>delta = <span style="color: #7f007f;">function</span>(x,y,th) {
  delta = (t(x) %*% ((x %*% t(th)) - y))
  <span style="color: #7f007f;">return</span>(t(delta))
}

<span style="color: #b22222;"># </span><span style="color: #b22222;">the cost for a given theta
</span>cost = <span style="color: #7f007f;">function</span>(x,y,th,m) {
  prt = ((x %*% t(th)) - y)
  <span style="color: #7f007f;">return</span>(1/m * (t(prt) %*% prt))
}

<span style="color: #b22222;"># </span><span style="color: #b22222;">run J for 50x, on each alpha
</span><span style="color: #7f007f;">for</span> (j <span style="color: #7f007f;">in</span> 1:length(alpha)) {
  <span style="color: #7f007f;">for</span> (i <span style="color: #7f007f;">in</span> 1:50) {
    J[i,j] = cost(x,y,theta,m) <span style="color: #b22222;"># </span><span style="color: #b22222;">capture the Cost
</span>    theta = theta - alpha[j] * 1/m * delta(x,y,theta)
  }
}

<span style="color: #b22222;"># </span><span style="color: #b22222;">lets have a look
</span>par(mfrow=c(3,2))
<span style="color: #7f007f;">for</span> (j <span style="color: #7f007f;">in</span> 1:length(alpha)) {
  plot(J[,j], type=<span style="color: #8b2252;">"l"</span>, xlab=paste(<span style="color: #8b2252;">"alpha"</span>, alpha[j]), ylab=expression(J(theta)))
}
</pre>




<p>
<img src="http://al3xandr3.github.com/img/ml-ex3-alpha.png" alt="http://al3xandr3.github.com/img/ml-ex3-alpha.png" />
</p>
<p>
alpha 1 seems to be the best.
</p>
<p>
Setting \(\alpha=1\) and running until convergence:
</p>



<pre class="src src-R"><span style="color: #b22222;"># </span><span style="color: #b22222;">running until convergence
</span><span style="color: #7f007f;">for</span> (i <span style="color: #7f007f;">in</span> 1:50000) {
  theta = theta - 1 * 1/m * delta(x,y,theta)
  <span style="color: #7f007f;">if</span> (abs(delta(x,y,theta)[2]) &lt; 0.0000001) {  
    <span style="color: #7f007f;">break</span> <span style="color: #b22222;"># </span><span style="color: #b22222;">to interrupt updates
</span>  }
}

<span style="color: #b22222;"># </span><span style="color: #b22222;">1. The final values of theta
</span>print(<span style="color: #8b2252;">"Theta:"</span>)
print(theta)

<span style="color: #b22222;"># </span><span style="color: #b22222;">2. The predicted price of a house with 1650 square feet and 3 bedrooms.
</span><span style="color: #b22222;"># </span><span style="color: #b22222;">Don't forget to scale your features when you make this prediction!
</span>print(<span style="color: #8b2252;">"Prediction for a house with 1650 square feet and 3 bedrooms:"</span>)
print(theta %*% c(1, (1650 - mean(dta[<span style="color: #8b2252;">"area"</span>]))/sd(dta[<span style="color: #8b2252;">"area"</span>]), (3 - mean(dta[<span style="color: #8b2252;">"bedrooms"</span>]))/sd(dta[<span style="color: #8b2252;">"bedrooms"</span>])))
</pre>



<pre class="example">
[1] "Theta:"
         [,1]     [,2]      [,3]
[1,] 340412.7 110631.1 -6649.474
[1] "Prediction for a house with 1650 square feet and 3 bedrooms:"
         [,1]
[1,] 293081.5
</pre>


</div>

</div>

<div class="outline-2" id="outline-container-3">
<h2 id="sec-3">Normal Equations </h2>
<div class="outline-text-2" id="text-3">


<p>
Given the cost function:
</p>


\[
J(\theta) = \frac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2
\]

<p>
Recall that this function returns how big is the error of our model vs the data. Thus our goal is to minimize it. And in order to find its minimum there is also a more direct approach (instead of using gradient descent) we can just calculate its derivative set it to 0 and find the value of theta:
</p>


\[
\frac{\delta}{\delta \theta_j} J(\theta_j) = 0
\]

<p>
thats for \(\theta_j\). We need of course to account for every j. 
</p>
<p>
If we write it down into matrix notation, calculate its derivatives and set it to 0, then the value of theta will be obtained with:
</p>


\[
\theta =  (X^T X)^{-1} (X^T y)
\]

<p>
That can be easily implemented like so:
</p>



<pre class="src src-R">x = matrix(c(rep(1,m), mydata$area, mydata$bedrooms), ncol=3)
y = matrix(mydata$price, ncol=1)
theta.normal = solve(t(x) %*% x) %*% (t(x) %*% y)

<span style="color: #b22222;"># </span><span style="color: #b22222;">1. In your program, use the formula above to calculate. Remember that
</span><span style="color: #b22222;"># </span><span style="color: #b22222;">while you don't need to scale your features, you still need to add 
</span><span style="color: #b22222;"># </span><span style="color: #b22222;">an intercept term.
</span>print(<span style="color: #8b2252;">"Theta:"</span>)
print(theta.normal)

<span style="color: #b22222;"># </span><span style="color: #b22222;">2. Once you have found  from this method, use it to make a price prediction 
</span><span style="color: #b22222;"># </span><span style="color: #b22222;">for a 1650-square-foot house with 3 bedrooms. Did you get the same price 
</span><span style="color: #b22222;"># </span><span style="color: #b22222;">that you found through gradient descent?
</span>print(<span style="color: #8b2252;">"Price prediction for a 1650-square-foot house with 3 bedrooms"</span>)
t(theta.normal) %*%  c(1, 1650, 3)
</pre>



<pre class="example">
[1] "Theta:"
           [,1]
[1,] 89597.9095
[2,]   139.2107
[3,] -8738.0191
[1] "Price prediction for a 1650-square-foot house with 3 bedrooms"
         [,1]
[1,] 293081.5
</pre>


<p>
Normal equations are more direct but also more costly than gradient descent to run, so depending on situation you might need to choose one or the other.
</p>

</div>

<div class="outline-4" id="outline-container-3_1">
<h4 id="sec-3_1">References </h4>
<div class="outline-text-4" id="text-3_1">

<ul>
<li><a href="http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=MachineLearning">OpenClassroom Machine Learning</a>
</li>
<li><a href="http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&amp;doc=exercises/ex3/ex3.html">Exercise 3: Multivariate Linear Regression</a>
</li>
</ul>

</div>
</div>
</div>
<div id="postamble">

</div>

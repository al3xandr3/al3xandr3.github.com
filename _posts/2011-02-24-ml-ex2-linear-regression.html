--- 
layout: post
title: Machine Learning Ex2 - Linear Regression
categories: 
- machinelearning
- ml
- linear
- regression
---







<p>
Andrew Ng has posted introductory machine learning lessons on the <a href="http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=MachineLearning">OpenClassRoom</a> site. I've followed the first set and will here try to solve <a href="http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&amp;doc=exercises/ex2/ex2.html">Exercise 2</a>.
</p>
<p>
The goal of exercise is to build a Linear Regression implementation. I will use R.
</p>


<script src="http://www.mathjax.org/mathjax/MathJax.js" type="text/javascript">
    MathJax.Hub.Config({
            jax: ["input/TeX", "output/HTML-CSS"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                     "TeX/noUndefined.js"],
        tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
        },
        showProcessingMessages: true,
        displayAlign: "left",
        displayIndent: "2em",
 
        "HTML-CSS": {
             scale: 100,
             availableFonts: ["STIX","TeX"],
             preferredFont: "TeX",
             webFont: "TeX",
             imageFont: "TeX",
             showMathMenu: true,
        },
        MMLorHTML: {
             prefer: {
                 MSIE:    "MML",
                 Firefox: "MML",
                 Opera:   "HTML",
                 other:   "HTML"
             }
        }
    });
</script>


<p>
The point of linear regression is to come up with a mathematical function that represents the data as best as possible, we will do that by fitting a straight line to the observed data.
</p>
<p>
This modeling will allow us, for example, to make predictions on new data.
</p>
<p>
For example, the data we are using are boys ages and their heights, so when we have a mathematical model we can then, given a new age, predict what is the height.
</p>

<div class="outline-2" id="outline-container-1">
<h2 id="sec-1">Data </h2>
<div class="outline-text-2" id="text-1">





<pre class="src src-R"><span style="color: #b22222;"># </span><span style="color: #b22222;">load the data
</span>mydata = read.csv(<span style="color: #8b2252;">"http://spreadsheets.google.com/pub?key=0AnypY27pPCJydDB4N3MxM0tENlk3UElnZ013cW1iM3c&amp;hl=en_GB&amp;single=true&amp;gid=0&amp;output=csv"</span>, header = <span style="color: #228b22;">TRUE</span>)

<span style="color: #b22222;"># </span><span style="color: #b22222;">include ggplot2
</span><span style="color: #008b8b;">library</span>(ggplot2)

ex2plot = ggplot(mydata, aes(x, y)) + geom_point() + 
       ylab(<span style="color: #8b2252;">'Height in meters'</span>) +
       xlab(<span style="color: #8b2252;">'Age in years'</span>)
</pre>




<p>
<img src="http://al3xandr3.github.com/img/ml-ex2-data.png" alt="http://al3xandr3.github.com/img/ml-ex2-data.png" />
</p>
</div>

</div>

<div class="outline-2" id="outline-container-2">
<h2 id="sec-2">Theory </h2>
<div class="outline-text-2" id="text-2">


<p>
The final result we will end up with is an equation of a line, that we call the hypothesis, lets have a look at how that looks like.
</p>
<p>
Assuming \(x_0 = 1\):
</p>


\[
h_\theta(x) = \theta_0 x_0 + \theta_1 x_1 + \theta_2 x_2 + ...
\]

<p>
That can be summarized by (last is in Matrix notation):
</p>


\[
h_\theta(x) = \sum_{i=0}^n \theta_i x_i = \theta^T x
\]

<p>
Matrix representation is useful because has good support in software tools.
</p>
<p>
To get our line well fitted with the data, we want to have the line closest to observed data points as possible, thus we can define a cost function that returns the difference of the real data(\(y^{(i)}\)) vs our line(\(h_\theta(x^{(i)}\)):
</p>


\[
J(\theta) = \frac{1}{2} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2
\]

\(i\) is each data example we have and \(m\) is their total.

<p>
This way we have a metric to check if we are getting closer or not.
</p>
<p>
So given \(J(\theta)\), we now have the goal of finding the smaller values possible out of it, and in fact thats exactly what the <a href="http://mathworld.wolfram.com/MethodofSteepestDescent.html">gradient descent algorithm does</a>; starting in a inicial guess it iterates to smaller and smaller values of a given function by following the <a href="http://www.wolframalpha.com/input/?i=Plot[{x^2,+2+x},+{x,+0,+2.2}]">direction of the derivative</a>. 
Thus we get a formula to update the \(x\) (direction) given a function we want to minimize(in this case the cost function \(J\)), in general form looks like 
\(x_i := x_{i-1} - \epsilon f^' (x_{i-1})\)

Applying to our case:
</p>


\[
\theta_j := \theta_j - \alpha \frac{\delta}{\delta \theta_j} J(\theta)
\]

<p>
And doing a bit of calculus on derivatives we get:
</p>


\[
\theta_j := \theta_j - \alpha \frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) x^{(i)}
\]

<p>
where \(\alpha\) defines the size of the convergence of \(\theta\).
</p>
<p>
Next step is to apply it.
</p>
</div>

</div>

<div class="outline-2" id="outline-container-3">
<h2 id="sec-3">Implementation (1st iteration) </h2>
<div class="outline-text-2" id="text-3">





<pre class="src src-R">alpha = 0.07
m = length(mydata$x)
theta = c(0,0)
x = mydata$x
y = mydata$y 
delta = <span style="color: #7f007f;">function</span>(x,y,th,m) {
  sum = 0
  <span style="color: #7f007f;">for</span> (i <span style="color: #7f007f;">in</span> 1:m) {
    sum = sum + (((t(th) %*% c(1,x[i])) - y[i]) * c(1,x[i]))
  }
  <span style="color: #7f007f;">return</span> (sum)
}

<span style="color: #b22222;"># </span><span style="color: #b22222;">1 iteration
</span>print(theta - alpha * 1/m * delta(x,y,theta,m))
</pre>



<pre class="example">
[1] 0.07452802 0.38002167
</pre>


<p>
Note that I am using a cycle for the Sum.
</p>
</div>

</div>

<div class="outline-2" id="outline-container-4">
<h2 id="sec-4">Matrix only Implementation (2nd iteration) </h2>
<div class="outline-text-2" id="text-4">


<p>
After having a peek at the <a href="http://openclassroom.stanford.edu/MainFolder/courses/MachineLearning/exercises/ex2materials/ex2.m">solution</a>, updated with full on matrix calculations(so can remove the cycle for the sum):
</p>


\[
\theta := \theta - \alpha \frac{1}{m} x^T (h_\theta(x) - y)
\]


<pre class="src src-R">alpha = 0.07
m = length(mydata$x)
theta = matrix(c(0,0), nrow=1)
x = matrix(c(rep(1,m), mydata$x), ncol=2)
y = matrix(mydata$y, ncol=1)
delta = <span style="color: #7f007f;">function</span>(x,y,th) {
  delta = (t(x) %*% ((x %*% t(th)) - y))
  <span style="color: #7f007f;">return</span>(t(delta))
}

<span style="color: #b22222;"># </span><span style="color: #b22222;">1 iteration
</span>print(theta - alpha * 1/m * delta(x,y,theta))
</pre>



:            [,1]      [,2]
: [1,] 0.07452802 0.3800217

</div>

</div>

<div class="outline-2" id="outline-container-5">
<h2 id="sec-5">Running until Convergence </h2>
<div class="outline-text-2" id="text-5">





<pre class="src src-R"><span style="color: #7f007f;">for</span> (i <span style="color: #7f007f;">in</span> 1:1500) {
  theta = theta - alpha * 1/m * delta(x,y,theta)
}
print(theta)
</pre>



<pre class="example">
          [,1]       [,2]
[1,] 0.7501504 0.06388338
</pre>



</div>

<div class="outline-3" id="outline-container-5_1">
<h3 id="sec-5_1">Fitted line </h3>
<div class="outline-text-3" id="text-5_1">





<pre class="src src-R">ex2plot + geom_abline(intercept=theta[1], slope=theta[2])
</pre>




<p>
<img src="http://al3xandr3.github.com/img/ml-ex2-fit.png" alt="http://al3xandr3.github.com/img/ml-ex2-fit.png" />
</p>
</div>
</div>

</div>

<div class="outline-2" id="outline-container-6">
<h2 id="sec-6">References </h2>
<div class="outline-text-2" id="text-6">

<ul>
<li><a href="http://www.math.umaine.edu/~hiebeler/comp/matlabR.html">MATLAB / R Reference, by David Hiebeler</a>
</li>
<li><a href="ftp://ftp.ams.org/pub/tex/doc/amsmath/short-math-guide.pdf">Short Math Guide for LaTex(.pdf)</a>
</li>
<li><a href="http://wims.unice.fr/wims/en_tool~linear~matmult.en.html">matrix multiplier tool</a>
</li>
</ul>
</div>
</div>

